{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "541e0da8",
   "metadata": {},
   "source": [
    "<img vspace=\"33px\" align=\"right\" src=\"https://www.munich-startup.de/wp-content/uploads/2019/03/TUM_logo-440x236.png\" width=\"120px\"/>\n",
    "<h1>Sign Language Production</h1>\n",
    "<h3>Applied Deep Learning for NLP</h3>\n",
    "<p><b>Diego Miguel Lozano</b> | <b>Wenceslao Villegas Marset</b></p>\n",
    "<p>March 9<sup>th</sup>, 2022</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afad8b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8172e26d",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "> ### [1. Introduction](#section_1)\n",
    ">> [**1.1 What is Sign Language Production (SLP)?**](#section_1_1)<br>\n",
    ">> [**1.2 What is the starting point for our project?**](#section_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca96727",
   "metadata": {},
   "source": [
    "<a id='section_1'></a>\n",
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b2c8e",
   "metadata": {},
   "source": [
    "<a id='section_1_1'></a>\n",
    "### 1.1 What is Sign Language Production (SLP)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37110ff",
   "metadata": {},
   "source": [
    "Sign Language Production focuses on translating spoken languages into sign languages and viceversa. According to the World Health Organization (WHO), in 2020 there were more than 466 million deaf people in the world [[1]](#ref_1). This area could be of great help for the hearing-impared community, being for that necessary the development of techniques for both recognition and production of sign languages.\n",
    "\n",
    "While the Sign Language Recognition has seen numerous advancements in the last years [[2](#ref_2), [3](#ref_3), [4](#ref_4), [5](#ref_5), [6](#ref_6), [7](#ref_7)], Sign Language Production is still a very challenging task, since it involves an interpretation between visual and linguistic information [[8]](#ref_8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438970b4",
   "metadata": {},
   "source": [
    "<a id='section_1_2'></a>\n",
    "### 1.2 What is the starting point for our project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731e567",
   "metadata": {},
   "source": [
    "As we just mentioned, SLP is complex and far from being solved. Nevertheless, there have recently been promising developments, such as the application of Transformer architectures to SLP, what has come to be called \"Progressive Transformers.\"\n",
    "\n",
    "In this project, we take the [source code](https://github.com/BenSaunders27/ProgressiveTransformersSLP) for the paper \"Progressive Transformers for End-to-End Sign Language Production\" [[9]](#ref_9) as the starting point.\n",
    "\n",
    "**TODO**: define exactly what the scope of our project is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd906eba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62948faf",
   "metadata": {},
   "source": [
    "# A brief intro to the \"Progressive Transformers for SLP\" project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe4a6ba",
   "metadata": {},
   "source": [
    "**TODO**: explain main aspects of the project (e.g., architecture, loss, etc.). Also mention the two approaches **text-gloss-pose** vs. **end-to-end text to pose**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c3a42c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cae32e",
   "metadata": {},
   "source": [
    "#  Using pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2d9e7",
   "metadata": {},
   "source": [
    "**TODO**: mention that the original project trains embeddings from scratch and that we could leverage pre-trained embeddings (e.g., BERT) to achieve better scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada48393",
   "metadata": {},
   "source": [
    "## Inside the SLP pretrained model vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94977066",
   "metadata": {},
   "source": [
    "The original project that we use as starting point provides a plain-text file [`src_vocab`](https://github.com/BenSaunders27/ProgressiveTransformersSLP/blob/master/Configs/src_vocab.txt) containing the vocabulary for which embeddings will then be trained. Here is a snippet of it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de685e28",
   "metadata": {},
   "source": [
    "```\n",
    "<unk>\n",
    "<pad>\n",
    "<s>\n",
    "</s>\n",
    "...\n",
    "AUSWAEHLEN\n",
    "BALD\n",
    "BEKOMMEN\n",
    "BITTE\n",
    "BODENSEE\n",
    "BRITANNIEN\n",
    "CHAOS\n",
    "DAMEN\n",
    "DAUERND\n",
    "DUENN\n",
    "...\n",
    "IRGENDWO\n",
    "J+L+I\n",
    "K+R+E+T+A\n",
    "...\n",
    "neg-DEUTSCH\n",
    "neg-FUENF\n",
    "neg-GEMUETLICH\n",
    "neg-GENUG\n",
    "neg-GLEICH\n",
    "neg-HART\n",
    "neg-HEISS\n",
    "...\n",
    "negalp-MUSS\n",
    "negalp-PASSEN\n",
    "negalp-STIMMT\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8097a094",
   "metadata": {},
   "source": [
    "Before jumping in and trying to directly use our pretrained embeddings, it is sensible to first analyze a bit how things work in the original project.\n",
    "\n",
    "From the previous vocabulary, there are three aspects that are worth mentioning:\n",
    "\n",
    "- Words such as `AUSWAEHLEN`, `DUENN` and `HEISS` give us a hint that **normalization** is used. A popular algorithm for German normalization is the [German2 snowball algorithm](https://snowballstem.org/algorithms/german2/stemmer.html) which defines the following mappings:\n",
    "  - 'ß' is replaced by 'ss'.\n",
    "  - 'ä', 'ö', 'ü' are replaced by 'a', 'o', 'u', respectively.\n",
    "  - 'ae' and 'oe' are replaced by 'a', and 'o', respectively.\n",
    "  - 'ue' is replaced by 'u', when not following a vowel or q.\n",
    "\n",
    "\n",
    "- As we saw during the seminar lectures, the **special tokens** `<unk>`, `<pad>`, `<s>`, `</s>` are also included in the dictionary. These tokens mark unknown words, padding, beginning of sequence (BOS), and end of sequence (EOS), respectively.\n",
    "\n",
    "\n",
    "- Some of the words in the vocabulary include the prefixes `neg-` and `negalp-`. We could guess that `neg-` simply means that the word is negated, e.g., `neg-GENUG`≡ `NICHT GENUG`, but what about the `negalp-` prefix? And also, what do words such as `J+L+I` and `K+R+E+T+A` mean? A look to the paper of the RWTH-PHOENIX-Weather dataset [[10]](#ref_10) (the first version of the dataset used to train the model) gives us the answer:\n",
    "\n",
    "\n",
    "<img width=\"400px\" src=\"./images/RWTH-PHOENIX-Weather-Annotation-Scheme.png\" alt=\"RWTH-PHOENIX-Weather Annotation Scheme\"/>\n",
    "<br>\n",
    "<div align=\"center\">Source <a href=\"#ref_10\">[10]</a>.</div>\n",
    "\n",
    "So in reality `neg-` means \"signs negated by headshake\" and `negalp-` \"signs negated by the alpha[betical] rule\" <sup>[1](note_1)</sup>. Words such as `K+R+E+T+A` are words (finger) spelled letter by letter.\n",
    "\n",
    "Interestingly enough, none of the other types of tokens appear in the source dictionary.\n",
    "\n",
    "---\n",
    "\n",
    "<a id='note_1'><sup>1</sup></a> In Sign Language, there are several ways of negating words. One of these ways is using a side-to-side headshake or a frown expression. Also, some verbs have their own negated forms, which is what `negalp-` indicates here [[11]](#ref_11)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7103277",
   "metadata": {},
   "source": [
    "### But... where is this vocabulary coming from?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad625ae",
   "metadata": {},
   "source": [
    "As it turns out, this vocabulary is simply made up of **glosses**. As we mentioned before, the original project proposes two ways of carrying out the translations from text to sign language.\n",
    "\n",
    "The first one consists in predicting glosses from text, and the translating the glosses to sign language (more precisely, coordinates).\n",
    "\n",
    "The second approach directly translates from text to sign language, in an end-to-end fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c494d0fc",
   "metadata": {},
   "source": [
    "## BERT it up!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d53989e",
   "metadata": {},
   "source": [
    "If something is clear is that BERT's dictionary will not contain glosses, let alone glosses specifically tailored to SLP.\n",
    "\n",
    "But then, how does BERT's vocabulary looks like? Let's take a look!\n",
    "\n",
    "Fortunately, Hugging Face's great API has got us covered: tokenizers expose their vocabulary through the method `get_vocab()`. Let's try with the model [`bert-base-german-cased`](https://huggingface.co/bert-base-german-cased)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e1d982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "# Load tokenizer from pretrained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ab3b0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[unused1974]', 28973),\n",
      " ('Andy', 22652),\n",
      " ('Konkur', 4558),\n",
      " ('Ferdinand', 8715),\n",
      " ('Besondere', 21453),\n",
      " ('##ago', 5572),\n",
      " ('01.', 9792),\n",
      " ('Pok', 11441),\n",
      " ('fordert', 8559),\n",
      " ('58', 8393),\n",
      " ('Rezens', 14475),\n",
      " ('klass', 4457),\n",
      " ('Österreich', 2661),\n",
      " ('Anhängern', 23532),\n",
      " ('[unused546]', 27545),\n",
      " ('Beschleun', 21506),\n",
      " ('Kaufpreis', 14774),\n",
      " ('bewirken', 22453),\n",
      " ('##fär', 25424),\n",
      " ('Honorar', 14227),\n",
      " ('bestehende', 7726),\n",
      " ('Personal', 3959),\n",
      " ('Verhandlungs', 16663),\n",
      " ('Rese', 14429),\n",
      " ('177', 18927),\n",
      " ('wirkte', 6420),\n",
      " ('schien', 12867),\n",
      " ('unglück', 21829),\n",
      " ('legitim', 20663),\n",
      " ('[unused1068]', 28067),\n",
      " ('##bek', 6295),\n",
      " ('##fahrts', 13135),\n",
      " ('Wörter', 14944),\n",
      " ('Abk', 14423),\n",
      " ('Rechnungen', 17913),\n",
      " ('[unused65]', 27064),\n",
      " ('kurze', 7478),\n",
      " ('[unused343]', 27342),\n",
      " ('Prinzessin', 15653),\n",
      " ('Periode', 21859)]\n"
     ]
    }
   ],
   "source": [
    "# Print some words of its dictionary\n",
    "pprint(list(tokenizer.get_vocab().items())[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c0f42",
   "metadata": {},
   "source": [
    "Above, we can see each token with its corresponding ID (just as we saw in the seminar lectures). However, there are two things that catch our attention...\n",
    "\n",
    "<br>\n",
    "\n",
    "**Why do some tokens start with \"##\"?**\n",
    "\n",
    "Well, this is just a way of indicating that this token is \"non-initial\", i.e., originally it belonged to a longer word (remember that usually Transformers work at a sub-word level).\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**What about the `[unused###]` tokens?**\n",
    "\n",
    "These are, unsurprisingly, tokens that are not used. However, they can come handy to add more words to the vocabulary:\n",
    "\n",
    "> Just replace the \"[unusedX]\" tokens with your vocabulary. Since these were not used they are effectively randomly initialized. ([source](https://github.com/google-research/bert/issues/9#issuecomment-434796704))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34450b1",
   "metadata": {},
   "source": [
    "As a side note, we would like to mention that someone took the time to explore BERT's vocabulary and wrote a great article about it. The article can be found at https://juditacs.github.io/2019/02/19/bert-tokenization-stats.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ac9238",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81caeb7",
   "metadata": {},
   "source": [
    "<a id='ref_1'>[1]</a> WHO: World Health Organization. Deafness and hearing loss. http://www.who.int/mediacentre/factsheets/fs300/en/, 2021\n",
    "\n",
    "<a id='ref_2'>[2]</a> Razieh Rastgoo, Kourosh Kiani, and Sergio Escalera. Multimodal deep hand sign language recognition in still images using restricted boltzmann machine. Entropy, 20, 2018.\n",
    "\n",
    "<a id='ref_3'>[3]</a> Razieh Rastgoo, Kourosh Kiani, and Sergio Escalera. Hand sign language recognition using multi-view hand skeleton. Expert Systems With Applications, 150, 2020.\n",
    "\n",
    "<a id='ref_4'>[4]</a> Razieh Rastgoo, Kourosh Kiani, and Sergio Escalera. Video based isolated hand sign language recognition using a deep cascaded model. Multimedia Tools And Applications, 79:22965–22987, 2020.\n",
    "\n",
    "<a id='ref_5'>[5]</a> Razieh Rastgoo, Kourosh Kiani, and Sergio Escalera. Hand pose aware multimodal isolated sign language recognition. Multimedia Tools And Applications, 80:127–163, 2021\n",
    "\n",
    "<a id='ref_6'>[6]</a> Mark Borg and Kenneth P. Camilleri. Phonologically-meaningful sub-units for deep learning-based sign language recognition. ECCV, 2020\n",
    "\n",
    "<a id='ref_7'>[7]</a> Agelos Kratimenos, Georgios Pavlakos, and Petros Maragos. 3d hands, face and body extraction for sign language recognition. ECCV, 2020.\n",
    "\n",
    "<a id='ref_8'>[8]</a> Razieh Rastgoo and Kourosh Kiani and Sergio Escalera and Mohammad Sabokrou. Sign Language Production: A Review. 2021.\n",
    "\n",
    "<a id='ref_9'>[9]</a> Saunders, Ben and Camgoz, Necati Cihan and Bowden, Richard. Progressive Transformers for End-to-End Sign Language Production. ECCV, 2020.\n",
    "\n",
    "<a id='ref_10'>[10]</a> J. Forster, C. Schmidt, T. Hoyoux, O. Koller, U. Zelle, J. Piater, and H. Ney. RWTH-PHOENIX-Weather: A Large Vocabulary Sign Language Recognition and Translation Corpus. https://www-i6.informatik.rwth-aachen.de/publications/download/773/Forster-LREC-2012.pdf In Language Resources and Evaluation (LREC), pages 3785-3789, Istanbul, Turkey, May 2012. \n",
    "\n",
    "<a id='ref_11'>[11]</a> \n",
    "\n",
    "<a id='ref_11'>[12]</a> \n",
    "\n",
    "<a id='ref_11'>[13]</a> \n",
    "\n",
    "<a id='ref_11'>[14]</a> Handspeak. Negation in Sign Language. https://www.handspeak.com/learn/index.php?id=156, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c8a156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
